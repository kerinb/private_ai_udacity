{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Introducing Federated Learning\n",
    "\n",
    "Federated Learning is a technique for training Deep Learning models on data to which you do not have access. Basically:\n",
    "\n",
    "Federated Learning: Instead of bringing all the data to one machine and training a model, we bring the model to the data, train it locally, and merely upload \"model updates\" to a central server.\n",
    "\n",
    "Use Cases:\n",
    "\n",
    "    - app company (Texting prediction app)\n",
    "    - predictive maintenance (automobiles / industrial engines)\n",
    "    - wearable medical devices\n",
    "    - ad blockers / autotomplete in browsers (Firefox/Brave)\n",
    "    \n",
    "Challenge Description: data is distributed amongst sources but we cannot aggregated it because of:\n",
    "\n",
    "    - privacy concerns: legal, user discomfort, competitive dynamics\n",
    "    - engineering: the bandwidth/storage requirements of aggregating the larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Introducing / Installing PySyft\n",
    "\n",
    "In order to perform Federated Learning, we need to be able to use Deep Learning techniques on remote machines. This will require a new set of tools. Specifically, we will use an extensin of PyTorch called PySyft.\n",
    "\n",
    "### Install PySyft\n",
    "\n",
    "The easiest way to install the required libraries is with [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/overview.html). Create a new environment, then install the dependencies in that environment. In your terminal:\n",
    "\n",
    "```bash\n",
    "conda create -n pysyft python=3\n",
    "conda activate pysyft # some older version of conda require \"source activate pysyft\" instead.\n",
    "conda install jupyter notebook\n",
    "pip install syft\n",
    "pip install numpy\n",
    "```\n",
    "\n",
    "If you have any errors relating to zstd - run the following (if everything above installed fine then skip this step):\n",
    "\n",
    "```\n",
    "pip install --upgrade --force-reinstall zstd\n",
    "```\n",
    "\n",
    "and then retry installing syft (pip install syft).\n",
    "\n",
    "If you are using Windows, I suggest installing [Anaconda and using the Anaconda Prompt](https://docs.anaconda.com/anaconda/user-guide/getting-started/) to work from the command line. \n",
    "\n",
    "With this environment activated and in the repo directory, launch Jupyter Notebook:\n",
    "\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "and re-open this notebook on the new Jupyter server.\n",
    "\n",
    "If any part of this doesn't work for you (or any of the tests fail) - first check the [README](https://github.com/OpenMined/PySyft.git) for installation help and then open a Github Issue or ping the #beginner channel in our slack! [slack.openmined.org](http://slack.openmined.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = th.tensor([1,2,3,4,5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 14:35:03.715316 26688 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# syft is an extension of torch, and we can create a hook, which modified pytrch with new functionalities\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Basic Remote Execution in PySyft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySyft => Remote PyTorch\n",
    "\n",
    "The essence of Federated Learning is the ability to train models in parallel on a wide number of machines. Thus, we need the ability to tell remote machines to execute the operations required for Deep Learning.\n",
    "\n",
    "Thus, instead of using Torch tensors - we're now going to work with **pointers** to tensors. Let me show you what I mean. First, let's create a \"pretend\" machine owned by a \"pretend\" person - we'll call him Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create a worker called bob\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{94921619732: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 61691997068: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 11385318184: tensor([1, 2, 3, 4, 5]),\n",
       " 45241903796: tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], grad_fn=<MmBackward>),\n",
       " 99444241652: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 86603234360: tensor([1, 2, 3, 4, 5]),\n",
       " 68742634147: tensor([1, 2, 3, 4, 5]),\n",
       " 96677417421: tensor([1, 1, 1, 1, 1]),\n",
       " 79140053018: tensor(20., grad_fn=<SumBackward0>),\n",
       " 75463042275: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 26691665293: tensor([[0.0536],\n",
       "         [0.9463]], requires_grad=True),\n",
       " 26351277307: tensor([[0.9997],\n",
       "         [0.9328],\n",
       "         [0.0670],\n",
       "         [0.0000]], grad_fn=<MmBackward>),\n",
       " 83584553351: tensor([1, 2, 3, 4, 5]),\n",
       " 71505585853: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 70719746265: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 14831972560: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 53835156723: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 7671182571: Parameter containing:\n",
       " tensor([[ 0.4356, -0.4142]], requires_grad=True),\n",
       " 84089531960: Parameter containing:\n",
       " tensor([0.2031], requires_grad=True),\n",
       " 62707912278: Parameter containing:\n",
       " tensor([[-0.2165,  0.6831]], requires_grad=True),\n",
       " 99133069425: Parameter containing:\n",
       " tensor([0.2272], requires_grad=True)}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bob has no objects\n",
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an oobject x\n",
    "x = th.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of pointer to the remote object (Wrapper)>[PointerTensor | me:73536145961 -> bob:38678573049]\n"
     ]
    }
   ],
   "source": [
    "# we send the bject x to bob, and store whatever is returned\n",
    "x = x.send(bob)\n",
    "# what is returned from this send function is a pointer to the remote object\n",
    "print(\"value of pointer to the remote object\", x)\n",
    "# a pointer here is a tensor, and thus has the full tensor API at its disposal\n",
    "# however, each command is serialised in JSON/tuple format sent to bob and bob executes the commands on our behalf\n",
    "# and bob returns to us,a pointer to the new object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{94921619732: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 61691997068: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 11385318184: tensor([1, 2, 3, 4, 5]),\n",
       " 45241903796: tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], grad_fn=<MmBackward>),\n",
       " 99444241652: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 86603234360: tensor([1, 2, 3, 4, 5]),\n",
       " 68742634147: tensor([1, 2, 3, 4, 5]),\n",
       " 96677417421: tensor([1, 1, 1, 1, 1]),\n",
       " 79140053018: tensor(20., grad_fn=<SumBackward0>),\n",
       " 75463042275: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 26691665293: tensor([[0.0536],\n",
       "         [0.9463]], requires_grad=True),\n",
       " 26351277307: tensor([[0.9997],\n",
       "         [0.9328],\n",
       "         [0.0670],\n",
       "         [0.0000]], grad_fn=<MmBackward>),\n",
       " 83584553351: tensor([1, 2, 3, 4, 5]),\n",
       " 71505585853: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 70719746265: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 14831972560: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 53835156723: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 7671182571: Parameter containing:\n",
       " tensor([[ 0.4356, -0.4142]], requires_grad=True),\n",
       " 84089531960: Parameter containing:\n",
       " tensor([0.2031], requires_grad=True),\n",
       " 62707912278: Parameter containing:\n",
       " tensor([[-0.2165,  0.6831]], requires_grad=True),\n",
       " 99133069425: Parameter containing:\n",
       " tensor([0.2272], requires_grad=True),\n",
       " 38678573049: tensor([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.location == bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38678573049"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.id_at_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73536145961"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.id\n",
    "# when we try to perform a command using x, its going to send a meesga to self.location and say\n",
    "# hey bob, find the tensor with this ID and execute the command I want you to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:me #objects:0>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all tensor is pysyft has an owner, since we have a client, owner default to be me.\n",
    "# this reveals another worker that was created when we first created and hooked pytorch in pysyft\n",
    "# this is called local_worker\n",
    "x.owner\n",
    "\n",
    "# what we really do when executing a command WRT x, we say, hey, local_worker, \n",
    "# contact bob and tellh im to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:me #objects:0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook.local_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:73536145961 -> bob:38678573049]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get is like, read etc, but it actually sends the data from bob to us, and bob no longer \n",
    "# carrying info on that tensor\n",
    "x = x.get()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{94921619732: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 61691997068: tensor([ 0.,  1., 23.,  3.,  1.,  3.,  3.]),\n",
       " 11385318184: tensor([1, 2, 3, 4, 5]),\n",
       " 45241903796: tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], grad_fn=<MmBackward>),\n",
       " 99444241652: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 86603234360: tensor([1, 2, 3, 4, 5]),\n",
       " 68742634147: tensor([1, 2, 3, 4, 5]),\n",
       " 96677417421: tensor([1, 1, 1, 1, 1]),\n",
       " 79140053018: tensor(20., grad_fn=<SumBackward0>),\n",
       " 75463042275: tensor([[1., 1.],\n",
       "         [0., 1.],\n",
       "         [1., 0.],\n",
       "         [0., 0.]], requires_grad=True),\n",
       " 26691665293: tensor([[0.0536],\n",
       "         [0.9463]], requires_grad=True),\n",
       " 26351277307: tensor([[0.9997],\n",
       "         [0.9328],\n",
       "         [0.0670],\n",
       "         [0.0000]], grad_fn=<MmBackward>),\n",
       " 83584553351: tensor([1, 2, 3, 4, 5]),\n",
       " 71505585853: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 70719746265: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 14831972560: tensor([[1., 1.],\n",
       "         [0., 1.]], requires_grad=True),\n",
       " 53835156723: tensor([[1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 7671182571: Parameter containing:\n",
       " tensor([[ 0.4356, -0.4142]], requires_grad=True),\n",
       " 84089531960: Parameter containing:\n",
       " tensor([0.2031], requires_grad=True),\n",
       " 62707912278: Parameter containing:\n",
       " tensor([[-0.2165,  0.6831]], requires_grad=True),\n",
       " 99133069425: Parameter containing:\n",
       " tensor([0.2272], requires_grad=True)}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Playing with Remote Tensors\n",
    "\n",
    "In this project, I want you to .send() and .get() a tensor to TWO workers by calling .send(bob,alice). This will first require the creation of another VirtualWorker called alice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this project here!\n",
    "# imports\n",
    "import torch as th\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 14:35:07.946596 26688 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# syft is an extension of torch, and we can create a hook, which modified pytrch with new functionalities\n",
    "# hook pytorch to pysyft\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.Tensor([0,1,23,3,1,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptr = x.send(bob, alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[MultiPointerTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:55711471073 -> bob:30801514335]\n",
       "\t-> (Wrapper)>[PointerTensor | me:40937031974 -> alice:96984699511]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = x_ptr.get()\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2., 46.,  6.,  2.,  6.,  6.])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr.get(sum_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Introducing Remote Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)\n",
    "y = th.tensor([1,1,1,1,1]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:11837244052 -> bob:76161182863]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:12715246602 -> bob:70984203469]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:93830579793 -> bob:28055667220]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.get()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:63375865604 -> bob:59238880103]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = th.add(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.get()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1.,2,3,4,5], requires_grad=True).send(bob)\n",
    "y = th.tensor([1.,1,1,1,1], requires_grad=True).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x + y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:24355474684 -> bob:81628450934]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Learn a Simple Linear Model\n",
    "\n",
    "In this project, I'd like for you to create a simple linear model which will solve for the following dataset below. You should use only Variables and .backward() to do so (no optimizers or nn.Modules). Furthermore, you must do so with both the data and the model being located on Bob's machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input = th.tensor([[1., 1], [0, 1], [1, 0], [0, 0]], requires_grad=True).send(bob)\n",
    "target = th.tensor([[1.], [1], [0], [0]]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = th.tensor([[0.], [0.]], requires_grad=True).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(0.5600)\n",
      "tensor(0.2432)\n",
      "tensor(0.1372)\n",
      "tensor(0.0849)\n",
      "tensor(0.0538)\n",
      "tensor(0.0344)\n",
      "tensor(0.0220)\n",
      "tensor(0.0141)\n",
      "tensor(0.0090)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pred = input.mm(weights)\n",
    "\n",
    "    loss = ((pred - target)**2).sum()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    weights.data.sub_(weights.grad * 0.1)\n",
    "    weights.grad *= 0\n",
    "\n",
    "    print(loss.get().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Garbage Collection and Common Errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "\n",
    "bob = bob.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:22357143700 -> bob:7623945081]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob = bob.clear_objects()\n",
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects\n",
    "# x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)\n",
    "y = th.tensor([1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "TensorsNotCollocatedException",
     "evalue": "You tried to call a method involving two tensors where one tensor is actually locatedon another machine (is a PointerTensor). Call .get() on the PointerTensor or .send(bob) on the other tensor.\n\nTensor A: [PointerTensor | me:27093792558 -> bob:28281769319]\nTensor B: tensor([1, 1, 1, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m                     new_self, new_args, new_kwargs = syft.frameworks.torch.hook_args.hook_method_args(\n\u001b[1;32m--> 657\u001b[1;33m                         \u001b[0mmethod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m                     )\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36mhook_method_args\u001b[1;34m(attr, method_self, args, kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# Try running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36mtwo_fold\u001b[1;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtwo_fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36mtuple_one_fold\u001b[1;34m(lambdas, args)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtuple_one_fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[1;32melse\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# And do this for all the args / rules provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"child\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"child\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPureTorchTensorFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTensorsNotCollocatedException\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-339-8c8f78e0676d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                     \u001b[1;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTensorsNotCollocatedException\u001b[0m: You tried to call a method involving two tensors where one tensor is actually locatedon another machine (is a PointerTensor). Call .get() on the PointerTensor or .send(bob) on the other tensor.\n\nTensor A: [PointerTensor | me:27093792558 -> bob:28281769319]\nTensor B: tensor([1, 1, 1, 1, 1])"
     ]
    }
   ],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)\n",
    "y = th.tensor([1,1,1,1,1]).send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "TensorsNotCollocatedException",
     "evalue": "You tried to call __add__ involving two tensors which are not on the same machine! One tensor is on <VirtualWorker id:bob #objects:0> while the other is on <VirtualWorker id:alice #objects:5>. Use a combination of .move(), .get(), and/or .send() to co-locate them to the same machine.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTensorsNotCollocatedException\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-341-8c8f78e0676d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m                 \u001b[1;31m# For inplace methods, just directly return self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pysyft\\lib\\site-packages\\syft\\frameworks\\torch\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPointerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mTensorsNotCollocatedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[1;31m# Send the command\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTensorsNotCollocatedException\u001b[0m: You tried to call __add__ involving two tensors which are not on the same machine! One tensor is on <VirtualWorker id:bob #objects:0> while the other is on <VirtualWorker id:alice #objects:5>. Use a combination of .move(), .get(), and/or .send() to co-locate them to the same machine."
     ]
    }
   ],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Toy Federated Learning\n",
    "\n",
    "Let's start by training a toy model the centralized way. This is about a simple as models get. We first need:\n",
    "\n",
    "- a toy dataset\n",
    "- a model\n",
    "- some basic training logic for training a model to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this project here!\n",
    "# imports\n",
    "import torch as th\n",
    "import syft as sy\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 14:59:51.385064 26688 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# A Toy Dataset\n",
    "data = th.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
    "target = th.tensor([[1.],[1], [0], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = th.tensor([[1., 1], [0, 1], [1, 0], [0, 0]], requires_grad=True)\n",
    "target = th.tensor([[1.], [1], [0], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a toy model\n",
    "model = nn.Linear(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6667)\n",
      "tensor(0.9569)\n",
      "tensor(0.5119)\n",
      "tensor(0.3232)\n",
      "tensor(0.2089)\n",
      "tensor(0.1357)\n",
      "tensor(0.0884)\n",
      "tensor(0.0578)\n",
      "tensor(0.0379)\n",
      "tensor(0.0249)\n",
      "tensor(0.0165)\n",
      "tensor(0.0110)\n",
      "tensor(0.0073)\n",
      "tensor(0.0049)\n",
      "tensor(0.0033)\n",
      "tensor(0.0023)\n",
      "tensor(0.0016)\n",
      "tensor(0.0011)\n",
      "tensor(0.0008)\n",
      "tensor(0.0005)\n"
     ]
    }
   ],
   "source": [
    "def train(iters=20):\n",
    "    for i in range(iters):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        print(loss.data)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bob = data[0:2].send(bob)\n",
    "target_bob = target[0:2].send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alice = data[2:4].send(alice)\n",
    "target_alice = target[2:4].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(data_bob, target_bob), (data_alice, target_alice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "opt = optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations=20):\n",
    "    model = nn.Linear(2, 1)\n",
    "    opt = optim.SGD(params=model.parameters(), lr=0.1)\n",
    "    for iter in range(iterations):\n",
    "        for _data, _target in datasets:\n",
    "\n",
    "            # send model to remote worker/data\n",
    "            model = model.send(_data.location)\n",
    "\n",
    "            # do normal training\n",
    "            opt.zero_grad()\n",
    "            pred = model(_data)\n",
    "            loss = ((pred - _target)**2).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # get smarter model back\n",
    "            model=model.get()\n",
    "\n",
    "            print(loss.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0617, requires_grad=True)\n",
      "tensor(2.5703, requires_grad=True)\n",
      "tensor(0.8727, requires_grad=True)\n",
      "tensor(1.5354, requires_grad=True)\n",
      "tensor(0.5297, requires_grad=True)\n",
      "tensor(0.9379, requires_grad=True)\n",
      "tensor(0.3180, requires_grad=True)\n",
      "tensor(0.5784, requires_grad=True)\n",
      "tensor(0.1928, requires_grad=True)\n",
      "tensor(0.3601, requires_grad=True)\n",
      "tensor(0.1184, requires_grad=True)\n",
      "tensor(0.2266, requires_grad=True)\n",
      "tensor(0.0738, requires_grad=True)\n",
      "tensor(0.1442, requires_grad=True)\n",
      "tensor(0.0468, requires_grad=True)\n",
      "tensor(0.0928, requires_grad=True)\n",
      "tensor(0.0303, requires_grad=True)\n",
      "tensor(0.0605, requires_grad=True)\n",
      "tensor(0.0200, requires_grad=True)\n",
      "tensor(0.0400, requires_grad=True)\n",
      "tensor(0.0134, requires_grad=True)\n",
      "tensor(0.0267, requires_grad=True)\n",
      "tensor(0.0092, requires_grad=True)\n",
      "tensor(0.0181, requires_grad=True)\n",
      "tensor(0.0064, requires_grad=True)\n",
      "tensor(0.0124, requires_grad=True)\n",
      "tensor(0.0045, requires_grad=True)\n",
      "tensor(0.0086, requires_grad=True)\n",
      "tensor(0.0032, requires_grad=True)\n",
      "tensor(0.0060, requires_grad=True)\n",
      "tensor(0.0023, requires_grad=True)\n",
      "tensor(0.0042, requires_grad=True)\n",
      "tensor(0.0017, requires_grad=True)\n",
      "tensor(0.0030, requires_grad=True)\n",
      "tensor(0.0013, requires_grad=True)\n",
      "tensor(0.0022, requires_grad=True)\n",
      "tensor(0.0009, requires_grad=True)\n",
      "tensor(0.0016, requires_grad=True)\n",
      "tensor(0.0007, requires_grad=True)\n",
      "tensor(0.0011, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Advanced Remote Execution Tools\n",
    "\n",
    "In the last section we trained a toy model using Federated Learning. We did this by calling .send() and .get() on our model, sending it to the location of training data, updating it, and then bringing it back. However, at the end of the example we realized that we needed to go a bit further to protect people privacy. Namely, we want to average the gradients BEFORE calling .get(). That way, we won't ever see anyone's exact gradient (thus better protecting their privacy!!!)\n",
    "\n",
    "But, in order to do this, we need a few more pieces:\n",
    "\n",
    "- use a pointer to send a Tensor directly to another worker\n",
    "\n",
    "And in addition, while we're here, we're going to learn about a few more advanced tensor operations as well which will help us both with this example and a few in the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 17:11:42.776902 18336 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# try this project here!\n",
    "# imports\n",
    "import torch as th\n",
    "import syft as sy\n",
    "\n",
    "# syft is an extension of torch, and we can create a hook, which modified pytrch with new functionalities\n",
    "# hook pytorch to pysyft\n",
    "hook = sy.TorchHook(th)\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseWorker.clear_objects of <VirtualWorker id:bob #objects:0>>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob.clear_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseWorker.clear_objects of <VirtualWorker id:alice #objects:0>>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.clear_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6821494378: tensor([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50534874292: (Wrapper)>[PointerTensor | alice:50534874292 -> bob:6821494378]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on alices machine, alice has a ptr from alice to bob, and our ptr no \n",
    "# longer points to bob, it points to alice, \n",
    "# when we send a message to contact this tensor, ie add tesnros, it would \n",
    "# first go to alice, and get processed there, and then forward the message\n",
    "# to bobs machine and process it there\n",
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:94195136172 -> alice:96426943998]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have a new ptr, still pointing to alices machine.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{60928308416: tensor([1, 2, 3, 4, 5]),\n",
       " 73019995941: tensor([ 2,  4,  6,  8, 10])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we look at bobs machine, we will see bob has 2 tensors, x and y\n",
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{88294058088: (Wrapper)>[PointerTensor | alice:88294058088 -> bob:60928308416],\n",
       " 96426943998: (Wrapper)>[PointerTensor | alice:96426943998 -> bob:73019995941]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alice ahs two tensors, but theyre pointers! \n",
    "# and y has the same dependancy chain as x\n",
    "alice._objects\n",
    "# if we have some other machine say; Jim, come along and say - Hey, alice, \n",
    "# tell bob I say hey - alice will refuse, and if jim said, hey bob\n",
    "# take out money from yours and alices joint account, bob will say no\n",
    "# since its jointly owned by bob and alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we did opertations between tensros with different tensor chains we \n",
    "# will get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jon = sy.VirtualWorker(hook, id='jon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:jon #objects:0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob.clear_objects()\n",
    "alice.clear_objects()\n",
    "jon.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob).send(alice)\n",
    "y = th.tensor([1,2,3,4,5]).send(bob).send(alice)\n",
    "# y = th.tensor([1,2,3,4,5]).send(bob).send(jon) # this will break if run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x +y\n",
    "\n",
    "# data is on bobs mnachine, and since jon and alice dony agree, the chain \n",
    "# is broken! \n",
    "\n",
    "# You tried to call __add__ involving two tensors which are not on the same \n",
    "# machine! One tensor is on <VirtualWorker id:alice #objects:2> while the \n",
    "# other is on <VirtualWorker id:jon #objects:1>. Use a combination of\n",
    "# .move(), .get(), and/or .send() to co-locate them to the same machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{52564484384: tensor([ 2,  4,  6,  8, 10])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70012606394: (Wrapper)>[PointerTensor | alice:70012606394 -> bob:52564484384]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-5e2cb1e6d58c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# bob now has x, but alice doesnt since she sent it to us!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# and we point directly to bobs data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# run it again, and its removed from bob too!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x = x.get()\n",
    "x\n",
    "# bob now has x, but alice doesnt since she sent it to us! \n",
    "# and we point directly to bobs data\n",
    "# run it again, and its removed from bob too! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Pointer Chain Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:alice #objects:0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob.clear_objects()\n",
    "alice.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice._objects\n",
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1,2,3,4,5]).send(bob).send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{23838917203: tensor([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3810586069: (Wrapper)>[PointerTensor | alice:3810586069 -> bob:23838917203]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:80743642792 -> alice:3810586069]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.remote_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{80743642792: tensor([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{38377260982: tensor([1, 2, 3, 4, 5, 6])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:80743642792 -> bob:80743642792]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.move(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:alice #objects:0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = th.tensor([1,2,3,4,5,6]).move(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for Federared Learning:\n",
    "\n",
    "1. Here, we want to do FL where the central server is not trusted. \n",
    "2. The grads should not come to the central server in raw format - we should use the .move command to move the gradients to one worker, sum them there, and then bring the btach to the central server - meaning they never see the raw gradients for the models \n",
    "\n",
    "The data here will be changed so its not longer using MNIST - since I cant figure out how to send the images to each worker - only work around would be to have each user read in X images etc from the data. \n",
    "\n",
    "The next approach to try is to set up some hard coded data objects - maybe say 3 workers, 2 learners and 1 central trusted worker - and the data will be similar to those above [[1, 0] ... etc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torch as th\n",
    "import syft as sy\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "try:\n",
    "    from syft.frameworks.torch.differential_privacy import pate\n",
    "except ImportError:\n",
    "    print(\"ERROR: syft not installed - Install syft and trying import again\")\n",
    "    !pip install syft\n",
    "    from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0629 16:06:58.204363 22028 hook.py:97] Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(th)\n",
    "\n",
    "worker_1 = sy.VirtualWorker(hook, id=\"w1\")\n",
    "worker_2 = sy.VirtualWorker(hook, id=\"w2\")\n",
    "worker_3 = sy.VirtualWorker(hook, id=\"w3\")\n",
    "worker_4 = sy.VirtualWorker(hook, id=\"w4\")\n",
    "worker_5 = sy.VirtualWorker(hook, id=\"w5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0629 16:06:58.371696 22028 base.py:628] Worker w2 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.372655 22028 base.py:628] Worker w3 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.373151 22028 base.py:628] Worker w4 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.373647 22028 base.py:628] Worker w1 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.374142 22028 base.py:628] Worker w3 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.375135 22028 base.py:628] Worker w4 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.376127 22028 base.py:628] Worker w2 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.376623 22028 base.py:628] Worker w1 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.377119 22028 base.py:628] Worker w4 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.377614 22028 base.py:628] Worker w2 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.378110 22028 base.py:628] Worker w3 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "W0629 16:06:58.378606 22028 base.py:628] Worker w1 already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:w4 #objects:8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_1.add_workers([worker_2, worker_3, worker_4])\n",
    "worker_2.add_workers([worker_1, worker_3, worker_4])\n",
    "worker_3.add_workers([worker_2, worker_1, worker_4])\n",
    "worker_4.add_workers([worker_2, worker_3, worker_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = th.tensor([[0., 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], \n",
    "                   [1., 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = th.tensor([[0.],[1],[1],[1], \n",
    "                    [1.],[1],[1],[1]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_data = input[0:2].send(worker_1)\n",
    "w2_data = input[2:4].send(worker_2)\n",
    "w3_data = input[4:6].send(worker_3)\n",
    "w4_data = input[6:8].send(worker_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_target = target[0:2].send(worker_1)\n",
    "w2_target = target[2:4].send(worker_2)\n",
    "w3_target = target[4:6].send(worker_3)\n",
    "w4_target = target[6:8].send(worker_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker 1:  {12373475095: Parameter containing:\n",
      "tensor([[-0.0438,  0.3927, -1.4824]], requires_grad=True), 82847667062: Parameter containing:\n",
      "tensor([-4.4506], requires_grad=True), 47428007536: tensor([[0., 0., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True), 66392323362: tensor([[0.],\n",
      "        [1.]], requires_grad=True), 13304156053: Parameter containing:\n",
      "tensor([[ 0.2107, -0.5582, -2.1015]], requires_grad=True), 59978876911: Parameter containing:\n",
      "tensor([-3.6290], requires_grad=True), 86087564980: tensor([[0.4023],\n",
      "        [0.8359]], grad_fn=<AddmmBackward>), 15823817582: tensor([[0., 0., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True), 77237561809: tensor([[0., 0., 0.],\n",
      "        [0., 0., 1.]], requires_grad=True), 80585001764: tensor([[0.],\n",
      "        [1.]], requires_grad=True)}\n",
      "worker 2:  {56785032151: tensor([[0., 1., 0.],\n",
      "        [0., 1., 1.]], requires_grad=True), 36793182926: tensor([[1.],\n",
      "        [1.]], requires_grad=True), 70112119781: Parameter containing:\n",
      "tensor([[ 0.2107, -4.5582, -2.0015]], requires_grad=True), 59312811298: Parameter containing:\n",
      "tensor([-3.4290], requires_grad=True), 46474863070: tensor([[0.2883],\n",
      "        [0.6988]], grad_fn=<AddmmBackward>), 12198758744: tensor([[0., 1., 0.],\n",
      "        [0., 1., 1.]], requires_grad=True), 46978625761: tensor([[1.],\n",
      "        [1.]], requires_grad=True)}\n",
      "worker 3:  {37910175079: tensor([[1., 0., 0.],\n",
      "        [1., 0., 1.]], requires_grad=True), 53792206367: tensor([[1.],\n",
      "        [1.]], requires_grad=True), 53854938989: Parameter containing:\n",
      "tensor([[-3.7893, -0.5582, -2.0015]], requires_grad=True), 18239405250: Parameter containing:\n",
      "tensor([-3.4290], requires_grad=True), 69373558238: tensor([[0.1236],\n",
      "        [0.5341]], grad_fn=<AddmmBackward>), 55350588305: tensor([[1., 0., 0.],\n",
      "        [1., 0., 1.]], requires_grad=True), 58614401920: tensor([[1.],\n",
      "        [1.]], requires_grad=True)}\n",
      "worker 4:  {52497900360: tensor([[1., 1., 0.],\n",
      "        [1., 1., 1.]], requires_grad=True), 42821637290: tensor([[1.],\n",
      "        [1.]], requires_grad=True), 66695533820: Parameter containing:\n",
      "tensor([[-3.7893, -4.5582, -2.0015]], requires_grad=True), 31981697008: Parameter containing:\n",
      "tensor([-3.4290], requires_grad=True), 54460219157: tensor([[-11.1765],\n",
      "        [-13.0780]], grad_fn=<AddmmBackward>), 71046071957: tensor([[-0.0621],\n",
      "        [ 0.3484]], grad_fn=<AddmmBackward>), 17515032464: tensor([[1., 1., 0.],\n",
      "        [1., 1., 1.]], requires_grad=True), 8846603492: tensor([[1.],\n",
      "        [1.]], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "print(\"worker 1: \", worker_1._objects)\n",
    "print(\"worker 2: \", worker_2._objects)\n",
    "print(\"worker 3: \", worker_3._objects)\n",
    "print(\"worker 4: \", worker_4._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: tensor(0.0599) w2: tensor(0.0059)\n",
      "w3: tensor(0.0085) w4: tensor(0.0033)\n",
      "w1: tensor(0.0595) w2: tensor(0.0061)\n",
      "w3: tensor(0.0083) w4: tensor(0.0033)\n",
      "w1: tensor(0.0593) w2: tensor(0.0062)\n",
      "w3: tensor(0.0082) w4: tensor(0.0032)\n",
      "w1: tensor(0.0590) w2: tensor(0.0063)\n",
      "w3: tensor(0.0081) w4: tensor(0.0032)\n",
      "w1: tensor(0.0588) w2: tensor(0.0064)\n",
      "w3: tensor(0.0079) w4: tensor(0.0032)\n",
      "w1: tensor(0.0585) w2: tensor(0.0065)\n",
      "w3: tensor(0.0079) w4: tensor(0.0032)\n",
      "w1: tensor(0.0584) w2: tensor(0.0066)\n",
      "w3: tensor(0.0078) w4: tensor(0.0032)\n",
      "w1: tensor(0.0582) w2: tensor(0.0067)\n",
      "w3: tensor(0.0077) w4: tensor(0.0032)\n",
      "w1: tensor(0.0580) w2: tensor(0.0067)\n",
      "w3: tensor(0.0076) w4: tensor(0.0032)\n",
      "w1: tensor(0.0579) w2: tensor(0.0068)\n",
      "w3: tensor(0.0076) w4: tensor(0.0032)\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    w1_model = model.copy().send(worker_1)\n",
    "    w2_model = model.copy().send(worker_2)\n",
    "    w3_model = model.copy().send(worker_3)\n",
    "    w4_model = model.copy().send(worker_4)\n",
    "\n",
    "    w1_opt = optim.SGD(params=w1_model.parameters(), lr=0.1)\n",
    "    w2_opt = optim.SGD(params=w2_model.parameters(), lr=0.1)\n",
    "    w3_opt = optim.SGD(params=w3_model.parameters(), lr=0.1)\n",
    "    w4_opt = optim.SGD(params=w4_model.parameters(), lr=0.1)\n",
    "    for i in range(10):\n",
    "        w1_opt.zero_grad()\n",
    "        w1_pred = w1_model(w1_data)\n",
    "        w1_loss = ((w1_pred - w1_target)**2).sum()\n",
    "        w1_loss.backward()\n",
    "        w1_opt.step()\n",
    "        w1_loss = w1_loss.get().data\n",
    "\n",
    "        w2_opt.zero_grad()\n",
    "        w2_pred = w2_model(w2_data)\n",
    "        w2_loss = ((w2_pred - w2_target)**2).sum()\n",
    "        w2_loss.backward()\n",
    "        w2_opt.step()\n",
    "        w2_loss = w2_loss.get().data\n",
    "\n",
    "        w3_opt.zero_grad()\n",
    "        w3_pred = w3_model(w3_data)\n",
    "        w3_loss = ((w3_pred - w3_target)**2).sum()\n",
    "        w3_loss.backward()\n",
    "        w3_opt.step()\n",
    "        w3_loss = w3_loss.get().data\n",
    "\n",
    "        w4_opt.zero_grad()\n",
    "        w4_pred = w4_model(w4_data)\n",
    "        w4_loss = ((w4_pred - w4_target)**2).sum()\n",
    "        w4_loss.backward()\n",
    "        w4_opt.step()\n",
    "        w4_loss = w4_loss.get().data\n",
    "\n",
    "    w1_model.move(worker_5)\n",
    "    w2_model.move(worker_5)\n",
    "    w3_model.move(worker_5)\n",
    "    w4_model.move(worker_5)\n",
    "\n",
    "    avg_weight = (w1_model.weight.data + w2_model.weight.data + w3_model.weight.data + w4_model.weight.data) / 4\n",
    "    model.weight.data.copy_(avg_weight.get())\n",
    "\n",
    "    avg_bias = (w1_model.bias.data + w2_model.bias.data + w3_model.bias.data + w4_model.bias.data) / 4\n",
    "    model.bias.data.copy_(avg_bias.get())\n",
    "    \n",
    "    print(\"w1: \" + str(w1_loss) + \" w2: \" + str(w2_loss))\n",
    "    print(\"w3: \" + str(w3_loss) + \" w4: \" + str(w4_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:w5 #objects:0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_1.clear_objects()\n",
    "worker_2.clear_objects()\n",
    "worker_3.clear_objects()\n",
    "worker_4.clear_objects()\n",
    "worker_5.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker 1:  {}\n",
      "worker 2:  {}\n",
      "worker 3:  {}\n",
      "worker 4:  {}\n",
      "worker 5:  {}\n"
     ]
    }
   ],
   "source": [
    "print(\"worker 1: \", worker_1._objects)\n",
    "print(\"worker 2: \", worker_2._objects)\n",
    "print(\"worker 3: \", worker_3._objects)\n",
    "print(\"worker 4: \", worker_4._objects)\n",
    "print(\"worker 5: \", worker_5._objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
